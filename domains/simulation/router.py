# domains/simulation/router.py
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
from openai import OpenAI, OpenAIError
import json
import os
import re
import logging
import asyncio

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

router = APIRouter()

# OpenAI API í‚¤ ì„¤ì • ë° ê²€ì¦
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    logger.warning("ê²½ê³ : OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    client = None
else:
    try:
        client = OpenAI(api_key=api_key)
        logger.info("OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
    except Exception as e:
        logger.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        client = None


# =============================================================================
# Pydantic ëª¨ë¸ ì •ì˜
# =============================================================================

class HintsRequest(BaseModel):
    scenarios: List[Dict[str, Any]]
    task: str


class EducationalAnalysisRequest(BaseModel):
    userid: str
    companyid: int
    userorder: List[int]
    reason: str
    responseTexts: Dict[str, str]
    hints: Dict[str, str]
    orderSelectionTime: int
    reasonWritingTime: int
    totalTimeSpent: int
    scenarioContents: Dict[str, str] = {}
    scenarioTags: Dict[str, str] = {}


# =============================================================================
# ì…ë ¥ ê²€ì¦ ë¡œì§
# =============================================================================

def validate_response_text(text: str) -> bool:
    """ì‘ë‹µ í…ìŠ¤íŠ¸ ìœ íš¨ì„± ê²€ì¦"""
    if not text or len(text.strip()) < 3:
        return False

    text_stripped = text.strip()

    # ììŒ/ëª¨ìŒë§Œ ìˆëŠ” ê²½ìš°
    korean_consonants = re.compile(r'^[ã„±-ã…ã…-ã…£\s]+$')
    if korean_consonants.match(text_stripped):
        return False

    # ë°˜ë³µ ë¬¸ì ì²´í¬
    repeated_char = re.compile(r'^(.)\1{2,}$')
    if repeated_char.match(text_stripped):
        return False

    # ìˆ«ìë§Œ ìˆëŠ” ê²½ìš°
    if text_stripped.replace(' ', '').isdigit():
        return False

    # íŠ¹ìˆ˜ë¬¸ìë§Œ ìˆëŠ” ê²½ìš°
    if re.match(r'^[^a-zA-Z0-9ê°€-í£\s]+$', text_stripped):
        return False

    # ì˜ë¯¸ì—†ëŠ” ì§§ì€ ë°˜ë³µ ì²´í¬
    if len(text_stripped) <= 15:
        char_count = {}
        for char in text_stripped.replace(' ', ''):
            char_count[char] = char_count.get(char, 0) + 1

        if char_count:
            max_char_count = max(char_count.values())
            total_chars = len(text_stripped.replace(' ', ''))
            if total_chars > 0 and max_char_count / total_chars > 0.6:
                return False

    # ë¬´ì˜ë¯¸í•œ íŒ¨í„´ë“¤ ì²´í¬
    meaningless_patterns = [
        r'^[ã…‹ã…]+$',
        r'^\w{1,2}$',
        r'^[.]+$',
        r'^[-]+$',
        r'^[!@#$%^&*()]+$',
    ]

    for pattern in meaningless_patterns:
        if re.match(pattern, text_stripped):
            return False

    return True


def get_invalid_responses(request: EducationalAnalysisRequest) -> List[str]:
    """ë¬´ì˜ë¯¸í•œ ì‘ë‹µì´ ìˆëŠ” ì‹œë‚˜ë¦¬ì˜¤ ID ëª©ë¡ ë°˜í™˜"""
    invalid_responses = []
    for scenario_id, text in request.responseTexts.items():
        if not validate_response_text(text):
            invalid_responses.append(scenario_id)
            logger.info(f"ë¬´ì˜ë¯¸í•œ ì‘ë‹µ ê°ì§€ - ì‹œë‚˜ë¦¬ì˜¤ {scenario_id}: '{text}'")
    return invalid_responses


# =============================================================================
# ì‹œë‚˜ë¦¬ì˜¤ ì •ë³´ ë§¤í•‘ ë¡œì§
# =============================================================================

def get_scenario_info_by_id(scenario_id: int, request: EducationalAnalysisRequest = None) -> Dict[str, str]:
    """ì‹œë‚˜ë¦¬ì˜¤ IDë¥¼ ë°›ì•„ì„œ ë‚´ìš©ê³¼ íƒœê·¸ ë°˜í™˜"""

    # ì‹¤ì œ ìš”ì²­ì—ì„œ ì‹œë‚˜ë¦¬ì˜¤ ì •ë³´ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
    if request and request.scenarioContents:
        scenario_id_str = str(scenario_id)
        if scenario_id_str in request.scenarioContents:
            content = request.scenarioContents[scenario_id_str]
            tags = request.scenarioTags.get(scenario_id_str, "")
            logger.info(f"ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ ì •ë³´ ì‚¬ìš© - ID {scenario_id}: {content}")
            return {
                "content": content,
                "tags": tags
            }

    # ì‹œë‚˜ë¦¬ì˜¤ ì •ë³´ê°€ ì—†ìœ¼ë©´ ì—ëŸ¬ ë°œìƒ
    raise HTTPException(
        status_code=400,
        detail=f"ì‹œë‚˜ë¦¬ì˜¤ ID {scenario_id}ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
    )


def build_scenarios_info_from_request(request: EducationalAnalysisRequest) -> str:
    """ì‹œë‚˜ë¦¬ì˜¤ ì •ë³´ ë¬¸ìì—´ ìƒì„±"""
    scenarios_info = ""

    logger.info(f"ì‹œë‚˜ë¦¬ì˜¤ ì •ë³´ êµ¬ì„± ì‹œì‘ - ì‚¬ìš©ì ìˆœì„œ: {request.userorder}")

    for i, scenario_id in enumerate(request.userorder, 1):
        scenario_info = get_scenario_info_by_id(scenario_id, request)
        scenarios_info += f"{i}. {scenario_info['content']} (íƒœê·¸: {scenario_info['tags']})\n"

    logger.info(f"ì™„ì„±ëœ ì‹œë‚˜ë¦¬ì˜¤ ì •ë³´:\n{scenarios_info}")
    return scenarios_info


def format_user_order_with_real_ids(userorder: List[int], request: EducationalAnalysisRequest = None) -> dict:
    """ì‚¬ìš©ì ìˆœì„œ ì •ë³´ í¬ë§·íŒ…"""

    formatted_order = []
    for i, scenario_id in enumerate(userorder):
        scenario_info = get_scenario_info_by_id(scenario_id, request)
        formatted_order.append({
            "priority": i + 1,
            "scenarioId": scenario_id,
            "scenarioName": scenario_info['content']
        })

    return {
        "order": userorder,
        "formattedOrder": formatted_order
    }


# =============================================================================
# GPT API í˜¸ì¶œ ë° ì‘ë‹µ ì²˜ë¦¬
# =============================================================================

async def get_gpt_recommended_order_detailed(scenarios_info: str) -> Dict[str, Any]:
    """GPT ì¶”ì²œ ìˆœì„œ ìƒì„±"""

    if not client:
        raise HTTPException(status_code=503, detail="AI ì„œë¹„ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

    prompt = f"""
ì¹´í˜ì—ì„œ ë‹¤ìŒ 5ê°€ì§€ ìƒí™©ì´ ë™ì‹œì— ë°œìƒí–ˆìŠµë‹ˆë‹¤:

{scenarios_info}

ì „ë¬¸ì ì¸ ì¹´í˜ ë§¤ë‹ˆì € ê´€ì ì—ì„œ ì´ ìƒí™©ë“¤ì„ ì²˜ë¦¬í•  ìµœì ì˜ ìš°ì„ ìˆœìœ„ë¥¼ ì •í•˜ê³ , 
ìš°ì„ ìˆœìœ„ íŒë‹¨ ê¸°ì¤€ê³¼ ìƒì„¸í•œ ì´ìœ ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.

**ì¤‘ìš”: ì¶”ì²œ ìˆœì„œëŠ” ë°˜ë“œì‹œ [1, 2, 3, 4, 5] ìˆ«ìë¡œ ë°°ì—´í•´ì£¼ì„¸ìš”.**

ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

{{
    "recommendedOrder": [1, 2, 3, 4, 5],
    "priorityCriteria": "ìš°ì„ ìˆœìœ„ë¥¼ ì •í•˜ëŠ” íŒë‹¨ ê¸°ì¤€ (í•œ ë¬¸ì¥ìœ¼ë¡œ ëª…í™•í•˜ê²Œ)",
    "detailedReasoning": "ìš°ì„ ìˆœìœ„ë¥¼ ì´ë ‡ê²Œ ì •í•œ ìƒì„¸í•œ ì´ìœ  (ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ)"
}}
"""

    gpt_response = ""

    try:
        logger.info("GPT ì¶”ì²œ ìˆœì„œ ìš”ì²­ ì¤‘...")
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ì¹´í˜ ìš´ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•­ìƒ ì •í™•í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."
                },
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=1000
        )

        gpt_response = response.choices[0].message.content.strip()
        logger.info(f"GPT ì¶”ì²œ ìˆœì„œ ì‘ë‹µ ë°›ìŒ: {len(gpt_response)}ì")

        parsed_response = json.loads(gpt_response)

        # ì‘ë‹µ ìœ íš¨ì„± ê²€ì¦
        if "recommendedOrder" not in parsed_response:
            raise ValueError("recommendedOrder í•„ë“œê°€ ì—†ìŒ")

        if not isinstance(parsed_response["recommendedOrder"], list):
            raise ValueError("recommendedOrderê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹˜")

        if len(parsed_response["recommendedOrder"]) != 5:
            raise ValueError("recommendedOrderì˜ ê¸¸ì´ê°€ 5ê°€ ì•„ë‹˜")

        logger.info("GPT ì¶”ì²œ ìˆœì„œ íŒŒì‹± ì„±ê³µ")
        return parsed_response

    except OpenAIError as e:
        logger.error(f"OpenAI API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=502, detail="AI ì„œë¹„ìŠ¤ ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤")
    except json.JSONDecodeError as e:
        logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        if gpt_response:
            logger.error(f"ì‘ë‹µ ë‚´ìš©: {gpt_response}")
        raise HTTPException(status_code=502, detail="AI ì‘ë‹µ í˜•ì‹ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤")
    except Exception as e:
        logger.error(f"ì¶”ì²œ ìˆœì„œ ìƒì„± ì‹¤íŒ¨: {e}")
        if gpt_response:
            logger.error(f"ì‘ë‹µ ë‚´ìš©: {gpt_response}")
        raise HTTPException(status_code=500, detail="ì¶”ì²œ ìˆœì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")


def parse_gpt_response_safely(gpt_response: str) -> Optional[Dict[str, Any]]:
    """GPT ì‘ë‹µ ì•ˆì „ íŒŒì‹±"""

    if not gpt_response or not gpt_response.strip():
        logger.error("GPT ì‘ë‹µì´ ë¹„ì–´ìˆìŒ")
        return None

    logger.info(f"íŒŒì‹±í•  GPT ì‘ë‹µ ê¸¸ì´: {len(gpt_response)}")
    logger.info(f"GPT ì‘ë‹µ ì‹œì‘ ë¶€ë¶„: {gpt_response[:200]}")

    try:
        # 1ë‹¨ê³„: ì§ì ‘ JSON íŒŒì‹±
        result = json.loads(gpt_response.strip())
        logger.info("âœ… ì§ì ‘ JSON íŒŒì‹± ì„±ê³µ")
        return result

    except json.JSONDecodeError as e:
        logger.warning(f"ì§ì ‘ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")

        # ì‘ë‹µ ì „ì²´ë¥¼ ë¡œê·¸ë¡œ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
        logger.error(f"íŒŒì‹± ì‹¤íŒ¨í•œ ì „ì²´ ì‘ë‹µ:\n{gpt_response}")

        try:
            # 2ë‹¨ê³„: JSON ì½”ë“œ ë¸”ë¡ ì¶”ì¶œ
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', gpt_response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                logger.info("JSON ì½”ë“œ ë¸”ë¡ ë°œê²¬, íŒŒì‹± ì‹œë„")
                return json.loads(json_str)

            # 3ë‹¨ê³„: ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ ì¤‘ê´„í˜¸ ì‚¬ì´ ì¶”ì¶œ
            first_brace = gpt_response.find('{')
            last_brace = gpt_response.rfind('}')

            if first_brace != -1 and last_brace != -1 and last_brace > first_brace:
                json_candidate = gpt_response[first_brace:last_brace + 1]
                logger.info(f"ì¤‘ê´„í˜¸ êµ¬ê°„ ì¶”ì¶œ: {len(json_candidate)}ì")
                logger.info(f"ì¶”ì¶œëœ JSON: {json_candidate[:300]}...")
                return json.loads(json_candidate)

        except json.JSONDecodeError as e2:
            logger.error(f"ëª¨ë“  íŒŒì‹± ì‹œë„ ì‹¤íŒ¨: {e2}")
            return None

    except Exception as e:
        logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ íŒŒì‹± ì˜¤ë¥˜: {e}")
        return None


# =============================================================================
# êµìœ¡ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ë° ë¡œì§
# =============================================================================

def generate_educational_analysis_prompt(request: EducationalAnalysisRequest, gpt_recommendation: dict,
                                         invalid_responses: List[str] = None):
    """êµìœ¡ìš© ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„± - ëª…í™•í•œ JSON êµ¬ì¡° ìš”êµ¬"""

    if invalid_responses is None:
        invalid_responses = get_invalid_responses(request)

    # ì‚¬ìš©ì ì‘ë‹µ ë¶„ì„
    user_responses_analysis = ""
    for i, scenario_id in enumerate(request.userorder, 1):
        scenario_info = get_scenario_info_by_id(scenario_id, request)
        user_text = request.responseTexts.get(str(scenario_id), "").strip()
        invalid_note = " [âš ï¸ ë¬´ì˜ë¯¸í•œ ì…ë ¥]" if str(scenario_id) in invalid_responses else ""
        user_responses_analysis += f"ì‹œë‚˜ë¦¬ì˜¤ {i}: {scenario_info['content']}{invalid_note}\nì‚¬ìš©ì ì‘ë‹µ: \"{user_text}\"\n\n"

    # ì‚¬ìš©ì ìˆœì„œ
    user_order_text = ""
    for i, scenario_id in enumerate(request.userorder):
        scenario_info = get_scenario_info_by_id(scenario_id, request)
        user_order_text += f"{i + 1}ìˆœìœ„: {scenario_info['content']}\n"

    # GPT ì¶”ì²œ ìˆœì„œ
    gpt_order_text = ""
    gpt_order = gpt_recommendation.get('recommendedOrder', [1, 2, 3, 4, 5])
    for i, position in enumerate(gpt_order, 1):
        if position <= len(request.userorder):
            actual_scenario_id = request.userorder[position - 1]
            scenario_info = get_scenario_info_by_id(actual_scenario_id, request)
            gpt_order_text += f"{i}ìˆœìœ„: {scenario_info['content']}\n"

    # ì•ˆì „í•œ ë¬¸ìì—´ ì²˜ë¦¬
    priority_criteria = gpt_recommendation.get('priorityCriteria', '').replace('"', "'")
    detailed_reasoning = gpt_recommendation.get('detailedReasoning', '').replace('"', "'")

    prompt = f"""
ì¹´í˜ ì‹œë®¬ë ˆì´ì…˜ êµìœ¡ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³  JSONìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.

=== ì‚¬ìš©ì ì •ë³´ ===
ì‚¬ìš©ì: {request.userid}
ìˆœì„œ ì„ íƒ ì‹œê°„: {request.orderSelectionTime}ì´ˆ
ì´ìœ  ì‘ì„± ì‹œê°„: {request.reasonWritingTime}ì´ˆ
ì„ íƒ ì´ìœ : "{request.reason}"

=== ì‚¬ìš©ìê°€ ì„ íƒí•œ ìˆœì„œ ===
{user_order_text}

=== AI ì¶”ì²œ ìˆœì„œ ===
{gpt_order_text}

=== ì‚¬ìš©ì ì‘ë‹µë“¤ ===
{user_responses_analysis}

**ì¤‘ìš” ìš”êµ¬ì‚¬í•­:**
1. strengthsëŠ” ì™„ì „í•œ ë¬¸ì¥ 2ê°œ ë˜ëŠ” 3ê°œë¡œ ì‘ì„± (ê° ë¬¸ì¥ì´ ëë‚˜ê³  ì½¤ë§ˆë¡œ êµ¬ë¶„)
2. learningDirectionsë„ ì™„ì „í•œ ë¬¸ì¥ 2ê°œ ë˜ëŠ” 3ê°œë¡œ ì‘ì„± (ê° ë¬¸ì¥ì´ ëë‚˜ê³  ì½¤ë§ˆë¡œ êµ¬ë¶„)
3. ëª¨ë“  ë¬¸ì¥ì€ "ìŠµë‹ˆë‹¤", "ì„¸ìš”", "ìš”" ë“±ìœ¼ë¡œ ì™„ì „íˆ ëë‚˜ì•¼ í•¨
4. JSON í˜•ì‹ì„ ì •í™•íˆ ì§€ì¼œì£¼ì„¸ìš”

ë‹¤ìŒê³¼ ê°™ì€ ì •í™•í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:

{{
  "participationFeedback": "ì°¸ì—¬ë„ì— ëŒ€í•œ ì™„ì „í•œ ë¬¸ë‹¨",
  "scenarioCoaching": {{
    "scenario1": ["ê°œì„ ì 1", "ê°œì„ ì 2"],
    "scenario2": ["ê°œì„ ì 1", "ê°œì„ ì 2"],
    "scenario3": ["ê°œì„ ì 1", "ê°œì„ ì 2"],
    "scenario4": ["ê°œì„ ì 1", "ê°œì„ ì 2"],
    "scenario5": ["ê°œì„ ì 1", "ê°œì„ ì 2"]
  }},
  "orderAnalysis": "ìˆœì„œ ì„ íƒì— ëŒ€í•œ ì™„ì „í•œ ë¬¸ë‹¨",
  "strengths": [
    "ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ëœ ê°•ì  í•˜ë‚˜ì…ë‹ˆë‹¤",
    "ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ëœ ê°•ì  ë‘˜ì…ë‹ˆë‹¤"
  ],
  "learningDirections": [
    "ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ëœ í•™ìŠµë°©í–¥ í•˜ë‚˜ì…ë‹ˆë‹¤",
    "ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ëœ í•™ìŠµë°©í–¥ ë‘˜ì…ë‹ˆë‹¤"
  ],
  "gptOrderDetails": {{
    "recommendedOrder": {gpt_recommendation.get('recommendedOrder', [1, 2, 3, 4, 5])},
    "formattedOrderList": [
      "1ìˆœìœ„: ì²«ë²ˆì§¸ ì‹œë‚˜ë¦¬ì˜¤",
      "2ìˆœìœ„: ë‘ë²ˆì§¸ ì‹œë‚˜ë¦¬ì˜¤", 
      "3ìˆœìœ„: ì„¸ë²ˆì§¸ ì‹œë‚˜ë¦¬ì˜¤",
      "4ìˆœìœ„: ë„¤ë²ˆì§¸ ì‹œë‚˜ë¦¬ì˜¤",
      "5ìˆœìœ„: ë‹¤ì„¯ë²ˆì§¸ ì‹œë‚˜ë¦¬ì˜¤"
    ]
  }},
  "gptReasoningDetails": {{
    "priorityCriteria": "{priority_criteria}",
    "detailedReasoning": "{detailed_reasoning}"
  }}
}}

ë°˜ë“œì‹œ ìœ„ì˜ JSON í˜•ì‹ë§Œ ì‚¬ìš©í•˜ê³ , ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
strengthsì™€ learningDirectionsì˜ ê° í•­ëª©ì€ ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ëë‚˜ì•¼ í•©ë‹ˆë‹¤.
"""

    return prompt


# =============================================================================
# ë©”ì¸ ì—”ë“œí¬ì¸íŠ¸ë“¤
# =============================================================================

@router.post("/get-hints")
async def get_hints_only(request: HintsRequest):
    """íŒíŠ¸ ìƒì„±"""

    if not client:
        raise HTTPException(status_code=503, detail="AI ì„œë¹„ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

    scenarios = request.scenarios
    task = request.task

    logger.info(f"íŒíŠ¸ ìš”ì²­ ë°›ìŒ: {len(scenarios)}ê°œ ì‹œë‚˜ë¦¬ì˜¤")

    if not scenarios:
        raise HTTPException(status_code=400, detail="ì‹œë‚˜ë¦¬ì˜¤ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

    if task != "generate_hints_only":
        raise HTTPException(status_code=400, detail="ì˜ëª»ëœ ì‘ì—… ìœ í˜•ì…ë‹ˆë‹¤")

    try:
        prompt = generate_hints_only_prompt(scenarios)

        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ì¹´í˜ ìš´ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‹¤ë¬´ì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ íŒíŠ¸ë¥¼ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì œê³µí•˜ì„¸ìš”."
                },
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=2000
        )

        gpt_response = response.choices[0].message.content
        logger.info(f"GPT íŒíŠ¸ ì‘ë‹µ ê¸¸ì´: {len(gpt_response)}")

        try:
            hints_result = json.loads(gpt_response)
        except json.JSONDecodeError:
            logger.error(f"íŒíŠ¸ JSON íŒŒì‹± ì‹¤íŒ¨. ì‘ë‹µ: {gpt_response}")
            raise HTTPException(status_code=502, detail="AI ì‘ë‹µ í˜•ì‹ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤")

        # ì‘ë‹µ êµ¬ì¡° ê²€ì¦
        if "responseHints" not in hints_result:
            logger.error(f"responseHints í•„ë“œ ì—†ìŒ. ì‘ë‹µ: {hints_result}")
            raise HTTPException(status_code=502, detail="AI ì‘ë‹µ êµ¬ì¡°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤")

        return hints_result

    except OpenAIError as e:
        logger.error(f"OpenAI API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=502, detail="AI ì„œë¹„ìŠ¤ ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤")
    except HTTPException:
        # ì´ë¯¸ ì ì ˆí•œ HTTPExceptionì´ë¯€ë¡œ ì¬ë°œìƒ
        raise
    except Exception as e:
        logger.error(f"íŒíŠ¸ ìƒì„± ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="íŒíŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")


def generate_hints_only_prompt(scenarios):
    """íŒíŠ¸ ì „ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""

    prompt = """ë‹¤ìŒì€ ì¹´í˜ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ìƒí™©ë“¤ì…ë‹ˆë‹¤. ê° ìƒí™©ì— ëŒ€í•œ ì‹¤ë¬´ì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê³ ê° ì‘ëŒ€ íŒíŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.

ã€ìƒí™© ëª©ë¡ã€‘
"""

    for i, scenario in enumerate(scenarios):
        scenario_id = scenario.get('scenarioId')
        content = scenario.get('scenarioContent', '')
        tags = scenario.get('scenarioTag', '')
        prompt += f"{scenario_id}. {content} (íƒœê·¸: {tags})\n"

    prompt += """
ê° ìƒí™©ë³„ë¡œ í˜„ì‹¤ì ì´ê³  ì‹¤ìš©ì ì¸ ê³ ê° ì‘ëŒ€ íŒíŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.
íŒíŠ¸ëŠ” ì‹¤ì œ ë§¤ì¥ì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ë©˜íŠ¸ë‚˜ í–‰ë™ ì§€ì¹¨ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{
    "responseHints": {
"""

    for i, scenario in enumerate(scenarios):
        scenario_id = scenario.get('scenarioId')
        if i == len(scenarios) - 1:
            prompt += f'        "{scenario_id}": "ì´ ìƒí™©ì— ëŒ€í•œ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì‘ëŒ€ íŒíŠ¸"\n'
        else:
            prompt += f'        "{scenario_id}": "ì´ ìƒí™©ì— ëŒ€í•œ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì‘ëŒ€ íŒíŠ¸",\n'

    prompt += """    }
}

ë°˜ë“œì‹œ ìœ„ì˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ê³ , ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
ê° íŒíŠ¸ëŠ” 50-80ì ë‚´ì™¸ì˜ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

    return prompt


@router.post("/educational-analysis")
async def educational_analysis(request: EducationalAnalysisRequest):
    """êµìœ¡ìš© ë¶„ì„"""

    if not client:
        raise HTTPException(status_code=503, detail="AI ë¶„ì„ ì„œë¹„ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

    logger.info(f"êµìœ¡ìš© ë¶„ì„ ìš”ì²­ - ì‚¬ìš©ì: {request.userid}")
    logger.info(f"ì„ íƒí•œ ìˆœì„œ: {request.userorder}")

    # ë¬´ì˜ë¯¸í•œ ì…ë ¥ ê²€ì¦
    invalid_responses = get_invalid_responses(request)
    if invalid_responses:
        logger.warning(f"ë¬´ì˜ë¯¸í•œ ì…ë ¥ ê°ì§€ - ì‹œë‚˜ë¦¬ì˜¤: {invalid_responses}")

    # ë„ˆë¬´ ë§ì€ ë¬´ì˜ë¯¸í•œ ì‘ë‹µì´ ìˆìœ¼ë©´ ì—ëŸ¬
    if len(invalid_responses) >= 4:
        raise HTTPException(
            status_code=400,
            detail="ì˜ë¯¸ìˆëŠ” ì‘ë‹µì„ ë” ë§ì´ ì‘ì„±í•´ì£¼ì„¸ìš”. í˜„ì¬ ë¶„ì„í•˜ê¸° ì–´ë ¤ìš´ ìƒíƒœì…ë‹ˆë‹¤."
        )

    try:
        # 1ë‹¨ê³„: ì‹œë‚˜ë¦¬ì˜¤ ì •ë³´ êµ¬ì„±
        logger.info("ğŸ”„ ì‹œë‚˜ë¦¬ì˜¤ ì •ë³´ êµ¬ì„± ì¤‘...")
        scenarios_info = build_scenarios_info_from_request(request)

        # 2ë‹¨ê³„: GPT ì¶”ì²œ ìˆœì„œ ìƒì„±
        logger.info("ğŸ”„ GPT ì¶”ì²œ ìˆœì„œ ìƒì„± ì¤‘...")
        gpt_recommendation = await get_gpt_recommended_order_detailed(scenarios_info)

        # 3ë‹¨ê³„: êµìœ¡ìš© ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±
        logger.info("ğŸ”„ êµìœ¡ìš© ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
        educational_prompt = generate_educational_analysis_prompt(request, gpt_recommendation, invalid_responses)

        # 4ë‹¨ê³„: GPT API í˜¸ì¶œ
        logger.info("ğŸ”„ GPT API í˜¸ì¶œ ì¤‘...")
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ì¹´í˜ êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì‹¤ì œ ì‘ë‹µì„ ë¶„ì„í•˜ì—¬ ê°œì¸í™”ëœ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”. ê°•ì ê³¼ í•™ìŠµë°©í–¥ì€ ë°˜ë“œì‹œ 2-3ê°œë§Œ ì œê³µí•˜ê³ , ëª¨ë“  ë¬¸ì¥ì€ ì™„ì „í•´ì•¼ í•©ë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."
                },
                {"role": "user", "content": educational_prompt}
            ],
            temperature=0.5,
            max_tokens=4000
        )

        gpt_response = response.choices[0].message.content
        logger.info(f"âœ… GPT êµìœ¡ ë¶„ì„ ì‘ë‹µ ê¸¸ì´: {len(gpt_response)}")

        # 5ë‹¨ê³„: JSON íŒŒì‹±
        analysis_result = parse_gpt_response_safely(gpt_response)

        if analysis_result is None:
            logger.error("JSON íŒŒì‹± ì™„ì „ ì‹¤íŒ¨")
            raise HTTPException(status_code=502, detail="AI ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

        # 6ë‹¨ê³„: í•„ìˆ˜ í•„ë“œ ê²€ì¦
        required_fields = ["participationFeedback", "scenarioCoaching", "orderAnalysis", "strengths",
                           "learningDirections"]
        for field in required_fields:
            if field not in analysis_result:
                raise HTTPException(status_code=502, detail=f"AI ì‘ë‹µì— {field} í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤")

        # 7ë‹¨ê³„: ì‚¬ìš©ì ìˆœì„œ ì •ë³´ ì¶”ê°€
        analysis_result["userOrder"] = format_user_order_with_real_ids(request.userorder, request)

        logger.info("âœ… êµìœ¡ ë¶„ì„ ì™„ë£Œ")
        return analysis_result

    except HTTPException:
        # ì´ë¯¸ ì ì ˆí•œ HTTPExceptionì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì¬ë°œìƒ
        raise
    except OpenAIError as e:
        logger.error(f"OpenAI API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=502, detail="AI ë¶„ì„ ì„œë¹„ìŠ¤ ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤")
    except json.JSONDecodeError as e:
        logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=502, detail="AI ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")
    except Exception as e:
        logger.error(f"êµìœ¡ ë¶„ì„ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="ë¶„ì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")